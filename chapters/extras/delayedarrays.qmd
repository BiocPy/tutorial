# DelayedArrays, in Python

This package implements classes for delayed array operations, mirroring the [Bioconductor package](https://bioconductor.org/packages/DelayedArray) of the same name.
It allows BiocPy-based packages to easily inteoperate with delayed arrays from the Bioconductor ecosystem,
with focus on serialization to/from file with [**chihaya**](https://github.com/ArtifactDB/chihaya)/[**rds2py**](https://github.com/BiocPy/rds2py)
and entry into [**tatami**](https://github.com/tatami-inc/tatami)-compatible C++ libraries via [**mattress**](https://github.com/BiocPy/mattress).

## Installation

This package is published to [PyPI](https://pypi.org/project/delayedarray/) and can be installed via the usual methods:

```bash
pip install delayedarray
```

## Quick start

We can create a `DelayedArray` from any object that respects the seed contract,
i.e., has the `shape`/`dtype` properties and supports NumPy slicing.
For example, a typical NumPy array qualifies:

```{python}
import numpy
x = numpy.random.rand(100, 20)
x
```

We can wrap this in a `DelayedArray` class:

```{python}
import delayedarray
d = delayedarray.wrap(x)
d
```

And then we can use it in a variety of operations.
For example, in genomics, a typical quality control task is to slice the matrix to remove uninteresting features (rows) or samples (columns):

```{python}
filtered = d[1:100:2,1:8]
filtered.shape
```

We then divide by the total sum of each column to compute normalized values between samples.

```{python}
total = filtered.sum(axis=0)
normalized = filtered / total
normalized.dtype
```

And finally we compute a log-transformation to get some log-normalized values for visualization.

```{python}
transformed = numpy.log1p(normalized)
transformed[1:5,:]
```

Each operation just returns a `DelayedArray` with an increasing stack of delayed operations, without evaluating anything or making any copies.
Check out the [documentation](https://biocpy.github.io/DelayedArray/) for more information.

## Extracting data

Users can process a `DelayedArray` by iteratively extracting contiguous blocks on a dimension of interest.
This "block processing" strategy saves memory by only realizing the delayed operations for a subset of the data,
while reducing overhead from repeated calls to the `extract_*_array`  functions.
For example, to iterate over the rows with 100 MB blocks:

```{python}
block_size = delayedarray.guess_iteration_block_size(d, dimension=0, memory=1e8)
block_coords = [ None, range(d.shape[1]) ]

for start in range(0, d.shape[0], block_size):
    end = min(d.shape[0], start + block_size)
    block_coords[0] = range(start, end)
    current = delayedarray.extract_dense_array(d, (*block_coords,))
```

This yields `current`, a NumPy array in Fortran storage order with the specified rows and columns.
For sparse arrays (where `is_sparse()` returns `True`), we can instead do:

```{python}
if delayedarray.is_sparse(d):
    current = delayedarray.extract_sparse_array(d, (*block_coords,))
```

This returns a `SparseNdarray` consisting of a tree of sparse vectors for the specified block.
(For the two-dimensional case, this is effectively a compressed sparse column matrix.)

More simply, users can just call `numpy.array()` to realize the delayed operations into a standard NumPy array for consumption.

```{python}
simple = numpy.array(x)
print(type(simple))
```

Or `delayedarray.create_dask_array()`, to obtain a **dask** array that contains the delayed operations:

:::{.callout-note}
Note: requires installation as 'delayedarray[dask]'.
:::

```{python}
dasky = delayedarray.create_dask_array(x)
print(type(dasky))
```

## Interoperability with other packages 

The general idea is that `DelayedArray`s should be a drop-in replacement for NumPy arrays, at least for [BiocPy](https://github.com/BiocPy) applications.
So, for example, we can stuff the `DelayedArray` inside a `SummarizedExperiment`:

```{python}
import summarizedexperiment as SE
se = SE.SummarizedExperiment({ "counts": filtered, "lognorm": transformed })
print(se)
```

One of the main goals of the **DelayedArray** package is to make it easier for Bioconductor developers to inspect the delayed operations.
(See the [developer notes](https://biocpy.github.io/DelayedArray/developers.html) for some comments on **dask**.)
For example, we can pull out the "seed" object underlying our `DelayedArray` instance:

```{python}
d.seed
```

Each layer has its own specific attributes that define the operation, e.g.,

```python
d.seed.subset
```

Recursively drilling through the object will eventually reach the underlying array(s):

```python
d.seed.seed.seed.seed.seed
```

All attributes required to reconstruct a delayed operation are public and considered part of the stable `DelayedArray` interface.

## Developing seeds

Any array-like object can be used as a "seed" in a `DelayedArray` provided it has the following:

- `dtype` and `shape` properties, like those in NumPy arrays.
- a method for the `extract_dense_array()` generic.

If the object may contain sparse data, it should also implement:

- a method for the `is_sparse()` generic.
- a method for the `extract_sparse_generic()` generic.

It may also be desirable to implement:

- a method for the `chunk_shape()` generic.
- a method for the `create_dask_array()` generic.
- a method for the `wrap()` generic.

Developers are referred to the [documentation for each generic](https://biocpy.github.io/DelayedArray/api/delayedarray.html) for more details.